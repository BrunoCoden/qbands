#!/usr/bin/env python3
"""
Realtime backtesting monitor for the Q-bands strategy.

This script keeps watching the live `tablaQ.csv` generated by
`script_principal_de_velas_solo_bandas.py`, re-runs the backtesting
logic each time new candles arrive, and appends every newly closed
trade to a separate CSV without touching Binance.
"""

from __future__ import annotations

import argparse
import os
import sys
import time
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple

import numpy as np
import pandas as pd
from dotenv import load_dotenv
from zoneinfo import ZoneInfo

# Allow imports from repo root.
ROOT_DIR = Path(__file__).resolve().parent.parent
if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))

from Backtesting.backtesting import Backtester  # noqa: E402
import alertsQ


DEFAULT_SOURCE = Path("tablaQ.csv")
DEFAULT_TRADES_OUT = Path("Backtesting/live_trades.csv")
DEFAULT_SUMMARY_OUT = Path("Backtesting/live_summary.csv")
DEFAULT_POLL_SECONDS = 60.0

load_dotenv()
TZ_NAME = os.getenv("TZ", "America/Argentina/Buenos_Aires").strip()
LOCAL_TZ = ZoneInfo(TZ_NAME)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Backtest en tiempo real sobre la tabla Q-bands en streaming."
    )
    parser.add_argument(
        "--source",
        type=Path,
        default=DEFAULT_SOURCE,
        help="Archivo CSV generado por el script principal (tablaQ.csv).",
    )
    parser.add_argument(
        "--trades-out",
        type=Path,
        default=DEFAULT_TRADES_OUT,
        help="Salida donde registrar las operaciones simuladas.",
    )
    parser.add_argument(
        "--summary-out",
        type=Path,
        default=DEFAULT_SUMMARY_OUT,
        help="Archivo donde loguear el resumen periódico (usar --no-summary para omitir).",
    )
    parser.add_argument(
        "--no-summary",
        action="store_true",
        help="No persistir el resumen periódico en disco.",
    )
    parser.add_argument(
        "--poll-seconds",
        type=float,
        default=DEFAULT_POLL_SECONDS,
        help="Segundos de espera entre recomputos.",
    )
    parser.add_argument(
        "--run-once",
        action="store_true",
        help="Procesa el CSV una sola vez y termina.",
    )
    parser.add_argument(
        "--print-summary",
        action="store_true",
        help="Mostrar el resumen por consola en cada ciclo.",
    )
    return parser.parse_args()


NUMERIC_COLUMNS = [
    "Open",
    "High",
    "Low",
    "Close",
    "Volume",
    "Value",
    "UpperMid",
    "ValueUpper",
    "LowerMid",
    "ValueLower",
    "UpperQ",
    "LowerQ",
    "TrendSMA",
]

TOUCH_COLUMNS = ["TouchUpperQ", "TouchLowerQ"]


def _load_table(path: Path) -> pd.DataFrame:
    if not path.exists():
        return pd.DataFrame()
    try:
        df = pd.read_csv(path)
    except pd.errors.EmptyDataError:
        return pd.DataFrame()
    except Exception as exc:  # pragma: no cover - defensive logging
        print(f"[WARN] No se pudo leer {path}: {exc}")
        return pd.DataFrame()

    if df.empty:
        return df

    dates = pd.to_datetime(df.get("Date"), errors="coerce")
    if dates.dt.tz is None:
        dates = dates.dt.tz_localize(LOCAL_TZ)
    else:
        dates = dates.dt.tz_convert(LOCAL_TZ)
    df["Date"] = dates

    for col in NUMERIC_COLUMNS:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        else:
            df[col] = np.nan

    for col in TOUCH_COLUMNS:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0).astype(int)
        else:
            df[col] = 0

    df = df.dropna(subset=["Date"]).sort_values("Date").reset_index(drop=True)
    return df


def _timestamp_iso(value: Any) -> str:
    if isinstance(value, pd.Timestamp):
        if value.tzinfo is None:
            value = value.tz_localize(LOCAL_TZ)
        return value.isoformat()
    try:
        ts = pd.to_datetime(value)
        if ts.tzinfo is None:
            ts = ts.tz_localize(LOCAL_TZ)
        return ts.isoformat()
    except Exception:
        return str(value)


def _trade_record(row: pd.Series) -> Dict[str, Any]:
    return {
        "side": row["side"],
        "context": row["context"],
        "entry_time": _timestamp_iso(row["entry_time"]),
        "exit_time": _timestamp_iso(row["exit_time"]),
        "entry_price": float(row["entry_price"]),
        "exit_price": float(row["exit_price"]),
        "exit_reason": row["exit_reason"],
        "profit_target_pct": float(row["profit_target_pct"]),
        "stop_pct": float(row["stop_pct"]),
        "pnl_pct": float(row["pnl_pct"]),
        "bars_held": int(row["bars_held"]),
        "reference_mid": float(row.get("reference_mid", float("nan"))),
        "reference_value": float(row.get("reference_value", float("nan"))),
        "logged_at": datetime.now(LOCAL_TZ).isoformat(),
    }


class TradeLog:
    def __init__(self, path: Path):
        self.path = path
        self.seen: Set[Tuple[str, str, str, str, str, str]] = set()
        self.path.parent.mkdir(parents=True, exist_ok=True)
        self._load_existing()

    def _load_existing(self) -> None:
        if not self.path.exists():
            return
        try:
            df = pd.read_csv(self.path)
        except Exception:
            return
        for row in df.itertuples():
            key = (
                getattr(row, "entry_time", ""),
                getattr(row, "exit_time", ""),
                getattr(row, "side", ""),
                getattr(row, "context", ""),
                str(getattr(row, "entry_price", "")),
                str(getattr(row, "exit_price", "")),
            )
            self.seen.add(key)

    def append_trades(self, trades: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        if not trades:
            return []
        new_records: List[Dict[str, Any]] = []
        for record in trades:
            key = (
                record.get("entry_time", ""),
                record.get("exit_time", ""),
                record.get("side", ""),
                record.get("context", ""),
                str(record.get("entry_price", "")),
                str(record.get("exit_price", "")),
            )
            if key in self.seen:
                continue
            self.seen.add(key)
            new_records.append(record)
        if not new_records:
            return []
        df = pd.DataFrame(new_records)
        write_header = not self.path.exists()
        df.to_csv(self.path, mode="a", header=write_header, index=False)
        return new_records

    @property
    def registered_trades(self) -> int:
        return len(self.seen)


class SummaryLog:
    def __init__(self, path: Optional[Path]):
        self.path = path
        if self.path:
            self.path.parent.mkdir(parents=True, exist_ok=True)

    def append_summary(self, summary: Dict[str, Any]) -> None:
        if not self.path:
            return
        converted: Dict[str, Any] = {}
        for key, value in summary.items():
            if isinstance(value, (np.floating, float)):
                converted[key] = float(value)
            elif isinstance(value, (np.integer, int)):
                converted[key] = int(value)
            else:
                converted[key] = value
        row: Dict[str, Any] = {
            "logged_at": datetime.now(LOCAL_TZ).isoformat(),
            **converted,
        }
        df = pd.DataFrame([row])
        write_header = not self.path.exists()
        df.to_csv(self.path, mode="a", header=write_header, index=False)


@dataclass
class MonitorState:
    last_rows: int = -1
    last_mtime: float = 0.0
    open_alerted: Set[Tuple[str, str, str, str]] = field(default_factory=set)


def process_once(
    source: Path,
    trade_log: TradeLog,
    summary_log: SummaryLog,
    state: MonitorState,
    print_summary: bool,
) -> None:
    df = _load_table(source)
    if df.empty:
        print(f"[INFO] Sin datos en {source}.")
        return

    try:
        stat = source.stat()
        mtime = stat.st_mtime
    except FileNotFoundError:
        mtime = 0.0

    if state.last_rows == len(df) and mtime <= state.last_mtime:
        return

    bt = Backtester(df)
    bt.run()

    current_open_keys: Set[Tuple[str, str, str, str]] = set()
    for pos in bt.open_positions:
        entry_time_iso = _timestamp_iso(pos.entry_time)
        key = (entry_time_iso, pos.side, pos.context, f"{pos.entry_price:.8f}")
        current_open_keys.add(key)
        if key not in state.open_alerted:
            alertsQ.send_trade_open_alert(
                side=pos.side,
                context=pos.context,
                entry_time=entry_time_iso,
                entry_price=pos.entry_price,
                reference_mid=pos.reference_mid,
                reference_value=pos.reference_value,
            )
    state.open_alerted = current_open_keys

    trades_df = bt.trades_dataframe()
    trade_records = [_trade_record(row) for row in trades_df.to_dict(orient="records")]
    new_trades = trade_log.append_trades(trade_records)
    if new_trades:
        print(f"[INFO] Registradas {len(new_trades)} operaciones nuevas (total={trade_log.registered_trades}).")
        for record in new_trades:
            alertsQ.send_trade_close_alert(record)

    summary = bt.summary()
    summary_log.append_summary(summary)
    if print_summary:
        print("[SUMMARY]", ", ".join(f"{k}={summary[k]:.2f}" if isinstance(summary[k], (int, float)) else f"{k}={summary[k]}" for k in summary))

    state.last_rows = len(df)
    state.last_mtime = mtime


def main() -> None:
    args = parse_args()

    trade_log = TradeLog(args.trades_out)
    summary_path = None if args.no_summary else args.summary_out
    summary_log = SummaryLog(summary_path)
    state = MonitorState()

    print(f"[INIT] Monitoreando {args.source} cada {args.poll_seconds:.0f}s.")
    print(f"[INIT] Log de trades: {args.trades_out}")
    if summary_path:
        print(f"[INIT] Log de resumen: {summary_path}")

    try:
        while True:
            process_once(args.source, trade_log, summary_log, state, args.print_summary)
            if args.run_once:
                break
            time.sleep(max(1.0, args.poll_seconds))
    except KeyboardInterrupt:
        print("\n[EXIT] Cortado por usuario.")


if __name__ == "__main__":
    main()
